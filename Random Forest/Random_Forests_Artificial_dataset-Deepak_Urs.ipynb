{"cells":[{"cell_type":"markdown","source":["## **Random Forest Model Implementation for artificial data**\n"],"metadata":{"id":"nMoHdn34LfGc"}},{"cell_type":"code","source":["import numpy as np\n","\n","class Node:\n","    def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n","        self.value = value\n","        self.left = left\n","        self.right = right\n","        self.threshold = threshold\n","        self.feature = feature\n","\n","    def check_node_leaf(self):\n","        return self.value is not None\n"],"metadata":{"id":"cTQFnQa_F4OW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Defining the Decision Tree Model Class**"],"metadata":{"id":"HJDjRJvSLlyl"}},{"cell_type":"code","source":["class DecisionTree:\n","    # class initialization\n","    def __init__(self, minimum_samples_for_split=5, depth_maximum=5, number_of_features=None):\n","        self.minimum_samples_for_split = minimum_samples_for_split\n","        self.depth_maximum = depth_maximum\n","        self.number_of_features = number_of_features\n","        self.root = None\n","\n","    # model fit method\n","    def fitting(self, X, y):\n","        if not self.number_of_features:\n","            self.number_of_features = X.shape[1]\n","        else:\n","            self.number_of_features = min(self.number_of_features, X.shape[1])\n","\n","        self.root = self.build_decision_tree(X, y)\n","\n","    # building of the decision tree\n","    def build_decision_tree(self, X, y, depth=0):\n","        number_of_samples, num_of_feats_procured = X.shape\n","        number_of_labels = len(np.unique(y))\n","        \n","        # 1. check the stopping criteria\n","        #Qn -> the order of the features selected by the tree and why it is correct\n","\n","        # if either of these below is true, it is a stopping criteria\n","        if (number_of_labels == 1 or  number_of_samples < self.minimum_samples_for_split or depth >= self.depth_maximum):\n","            leaf_value = self.prominent_feature(y)\n","            tempRes = Node(value=leaf_value)\n","            return tempRes\n","\n","        # to select random number of features in a single time\n","        feature_indexes = np.random.choice(num_of_feats_procured, self.number_of_features, replace=False)\n","\n","        # 2. find the best split (to keep the tree growing)\n","        feat_best, thresh_best = self.calculate_split_best(X, y, feature_indexes)\n","\n","        # create child nodes\n","        indexes_left_side, indexes_right_side = self.find_split(X[:, feat_best], thresh_best)\n","        subtree_right = self.build_decision_tree(X[indexes_right_side, :], y[indexes_right_side], depth+1)\n","        subtree_left = self.build_decision_tree(X[indexes_left_side, :], y[indexes_left_side], depth+1)\n","\n","        return Node(feat_best, thresh_best, subtree_left, subtree_right)\n","    \n","    # model prediction code\n","    def prediction_calculation(self, X):\n","        return np.array([self.tree_traversal(x, self.root) for x in X])\n","\n","    def tree_traversal(self, x, node):\n","        if node.check_node_leaf():\n","            return node.value\n","\n","        if node.threshold >= x[node.feature]:\n","            return self.tree_traversal(x, node.left)\n","\n","        return self.tree_traversal(x, node.right)\n","\n","    # below is the list of all the helper functions\n","\n","    # we find the best split available amongst all the available splits\n","    def calculate_split_best(self, X, y, feature_indexes):\n","        index_threshold, threshold_split = None, None\n","        gain_initial = -1\n","        \n","\n","        for feat_idx in feature_indexes:\n","            X_column = X[:, feat_idx]\n","            thresholds = np.unique(X_column)\n","\n","            for thr in thresholds:\n","                # calculate the information gain for deciding the best-split\n","                gain = self.info_gain(y, X_column, thr)\n","\n","                if gain > gain_initial:\n","                    gain_initial = gain\n","                    index_threshold = feat_idx\n","                    threshold_split = thr\n","\n","        return index_threshold, threshold_split\n","\n","    # computing the information-gain of the data\n","    def info_gain(self, y, X_column, threshold):\n","        parent_entropy = self.compute_entropy(y)\n","\n","        # create children\n","        indexes_left_side, indexes_right_side = self.find_split(X_column, threshold)\n","\n","        # if info gain is 0\n","        if len(indexes_left_side) == 0 or len(indexes_right_side) == 0:\n","            return 0\n","\n","        # calculate the weighted avg. entropy of children\n","        total_number = len(y)\n","\n","        # getting the length/count of left and right indexes\n","        length_right = len(indexes_right_side)\n","        length_left = len(indexes_left_side)\n","\n","        # num of left and right idxs entropies\n","        entropy_left, right_entropy = self.compute_entropy(y[indexes_left_side]), self.compute_entropy(y[indexes_right_side])\n","\n","        #calc. child entropy\n","        child_entropy = (length_left/total_number) * entropy_left + (length_right/total_number) * right_entropy\n","\n","        # calculate the Information Gain\n","        information_gain = parent_entropy - child_entropy\n","        return information_gain\n","\n","    # deciding the split of the data\n","    def find_split(self, X_column, split_thresh):\n","        # here the right and left indices split is decided\n","        indexes_right_side = np.argwhere(split_thresh < X_column).flatten()\n","        indexes_left_side = np.argwhere(split_thresh >= X_column).flatten()\n","        \n","        return indexes_left_side, indexes_right_side\n","\n","    # calculation of entropy of data\n","    # minor change here with respect to real-world data as data processing(type casting) has to be done\n","    def compute_entropy(self, y):\n","        flatArray = [int(val) for sublist in y for val in sublist]\n","        \n","        counts = {}\n","        for val in flatArray:\n","            if val in counts:\n","                counts[val] += 1\n","            else:\n","                counts[val] = 1\n","        count = [counts.get(i, 0) for i in range(max(flatArray)+1)]\n","\n","        ps = []\n","        for i in count:\n","            ps.append(round(i/len(count), 5))\n","\n","        # entropy formula\n","        res = -np.sum([p * np.log(p) for p in ps if p > 0])\n","        return res\n","\n","    # deciding the most common feature for deciding the leaf node\n","    def prominent_feature(self, y):\n","        ctr = {}\n","\n","        # creating a dictionary to maintain frequency\n","        for i in y:\n","            if str(i) not in ctr:\n","                ctr[str(i)] = 1\n","            else:\n","                ctr[str(i)] += 1\n","\n","        # class decision logic\n","        if '1' not in ctr:\n","            return 2\n","        elif '2' not in ctr:\n","            return 1\n","        elif '1' in ctr and '2' in ctr:\n","            if ctr['1'] > ctr['2']:\n","                return 1\n","            else:\n","                return 2\n"],"metadata":{"id":"ollrNEd5F-TP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Defining the RandomForest class**"],"metadata":{"id":"6EN3SJBrLrH2"}},{"cell_type":"code","source":["# from DecisionTrees import DecisionTree\n","import numpy as np\n","from collections import Counter\n","\n","class RandomForest:\n","    # initializing the random forest\n","    def __init__(self, number_of_trees=10, depth_maximum=10, minimum_samples_for_split=2, n_feature=None):\n","        self.depth_maximum = depth_maximum\n","        self.minimum_samples_for_split = minimum_samples_for_split\n","        self.number_of_features = n_feature\n","        self.number_of_trees = number_of_trees\n","        self.trees = []\n","\n","    # model fit\n","    def fitting(self, X, y):\n","        self.trees = []\n","        for _ in range(self.number_of_trees):\n","            tree_result = DecisionTree(depth_maximum=self.depth_maximum, minimum_samples_for_split= self.minimum_samples_for_split, number_of_features= self.number_of_features)\n","            samples_X, samples_Y = self.sampling_bootstrap(X, y)\n","            tree_result.fitting(samples_X, samples_Y)\n","            self.trees.append(tree_result)\n","\n","    # performing bootstrap smpling\n","    def sampling_bootstrap(self, X, y):\n","        n_samples = 12\n","        # POINT FOR RANDOMEESS  IN DATA\n","        idxs = np.random.choice(X.shape[0], n_samples, replace=True)\n","        return X[idxs], y[idxs]\n","\n","    # calculating the prominent feature\n","    def prominent_feature(self, y):\n","        counter = Counter(y)\n","        most_common = counter.most_common(1)[0][0]\n","        return most_common\n","        \n","    # calculating the prediction\n","    def prediction_calculation(self, X):\n","        predictions_results = np.array([tree.prediction_calculation(X) for tree in self.trees])\n","        prediction_of_trees = np.swapaxes(predictions_results, 0, 1)\n","        predictions_results = np.array([self.prominent_feature(pred) for pred in prediction_of_trees])\n","        return predictions_results"],"metadata":{"id":"xOMQaPfhGUXW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## The below code is for testing the above implementations"],"metadata":{"id":"WjZty927LuVF"}},{"cell_type":"markdown","source":["**Adding the necessary imports**"],"metadata":{"id":"8DXFEMsXLxpU"}},{"cell_type":"code","source":["import numpy as np\n","# from RandomForests import RandomForest\n","import pandas as pd\n","\n","# for pre-processing, we are defining the MinMaxScaler\n","class MinMaxScaler:\n","    def __init__(self, feature_range=(0, 1)):\n","        self.feature_range = feature_range\n","    \n","    def fit(self, data):\n","        self.min_values = np.min(data, axis=0)\n","        self.max_values = np.max(data, axis=0)\n","        \n","    def transform(self, data):\n","        scaled_data = (data - self.min_values) / (self.max_values - self.min_values)\n","        scaled_data = scaled_data * (self.feature_range[1] - self.feature_range[0]) + self.feature_range[0]\n","        return scaled_data\n","    \n","    def fit_transform(self, data):\n","        self.fit(data)\n","        return self.transform(data)\n"],"metadata":{"id":"KR9ohQxGGg01"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Necessary data imports**"],"metadata":{"id":"D2H86829L31n"}},{"cell_type":"code","source":["data1 = pd.read_csv('./implementation_correctness_dataset.csv')\n","data2 = pd.read_csv('./implementation_correctness_dataset-test.csv')"],"metadata":{"id":"H3dC_0NGGzoi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Preparing the data**"],"metadata":{"id":"_LL9Y1lmL-dT"}},{"cell_type":"code","source":["# train data\n","X1 = data1.iloc[:, [0,1]].values\n","y1 = data1.iloc[:, [2]].values\n","\n","# test data\n","X_test2 = data2.iloc[:, [0,1]].values\n","y_test2 = data2.iloc[:, [2]].values\n","\n","X1d = np.array(X1)\n","y1d = np.array(y1)\n","\n","scaler = MinMaxScaler(feature_range=(0,1))\n","scaled_data_X1 = scaler.fit_transform(X1)\n","scaled_data_y1 = scaler.fit_transform(y1)\n"],"metadata":{"id":"VEtJyrTUG3zQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Defining accuracy**"],"metadata":{"id":"j3rW1wMWMDEA"}},{"cell_type":"markdown","source":["**Executing the Random forest model for the prediction**"],"metadata":{"id":"tV9DRbiQMNGU"}},{"cell_type":"code","source":["clf = RandomForest(number_of_trees=20)\n","clf.fitting(scaled_data_X1, scaled_data_y1)\n","predictions = clf.prediction_calculation(X_test2)\n","print('Class predictions on artificial dataset - Class:', predictions)"],"metadata":{"id":"sZ8x5UaXG8of","outputId":"c47d1141-8497-400c-a26b-23cabf5111e5","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Class predictions on artificial dataset - Class: [2]\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}